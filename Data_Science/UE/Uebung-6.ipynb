{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 6\n",
    "\n",
    "**Gruppenname:**\n",
    "\n",
    "*Name Ihrer Gruppe*\n",
    "\n",
    "Gehen Sie wie folgt vor:\n",
    "\n",
    "1. Bitte benennen Sie jetzt dieses Jupyter Notebook um (z.B. über `File -> Rename`):\n",
    "\n",
    "   Namensschema: `Gruppenname-X`. Ersetzen Sie \"X\" mit der oben angegebenen Nummer der Übung.\n",
    "\n",
    "   - Beispiel 1: Team REZA bearbeitet Übung 2. Das Notebook heißt: REZA-2.\n",
    "   - Beispiel 2: Sie sind keinem Team zugeordnet (nicht empfehlenswert) und bearbeiten Übung 2: Ihr Notebook heißt: Nachname-2.\n",
    "\n",
    "\n",
    "2. Tragen Sie Ihren Gruppennamen auch ganz oben bei \"Name Ihrer Gruppe\" ein.\n",
    "\n",
    "3. Bearbeiten Sie dann dieses Notebook. Vergessen Sie dabei nicht, das Jupyter Notebook regelmäßig zu speichern (z.B. über `Strg + S` oder über `File -> Save and Checkpoint`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Staudamm - Revisited\n",
    "\n",
    "* In dieser Übung geht es darum, Sie mit der Python Machine Learning Bibliothek [scikit-learn](https://scikit-learn.org/stable/) vertraut zu machen, die wir in manchen der kommenden Übungen benötigen werden. Scikit-Learn ist eine beliebte Machine Learning Bibliothek, auf die Sie zwangsläufig treffen, wenn Sie Ihre Projekte in Python Implementieren. Um Sie mit Scikit-Learn vertraut zu machen, beschäftigen wir uns weiter mit dem Lernproblem aus **Übung 5**. Diese Übung ist besonders wichtig für Ihre weitere Vorbereitung. Sie zeigt ein klassisches Vorgehen im Machine Learning.\n",
    "* Obwohl Sie in dieser Übung Scikit-Learn kennenlernen werden, mit der Sie viele Aufgaben schnell erledigen können, werden Sie in den kommenden Übungen trotzdem Methoden auch selbst implementieren. Dies dient dazu, Ihren Lernerfolg zu erhöhen.\n",
    "\n",
    "Sie haben in der Vorlesung gelernt, dass es viele verschiedene Regularisierungstechniken gibt. Unter anderem lässt sich die strikte Beschränkung der Modellordnung (hier: der Ordnung $Q$ der Polynome) als Regularisierung unseres Hypothesensets interpretieren. Im Vergleich zu Übung 5.1 werden wir hier untersuchen, wie wir sowohl den Parameter $\\lambda$ für die Weight Decay-Regularisierung als auch den Parameter $Q$ für die Polynomordnung gleichzeitig einstellen können. Diese Parameter $(Q, \\lambda)$ bilden eine Parameterlandschaft, die wir untersuchen werden. Dazu werden wir in diese Landschaft ein Gitter (grid) legen, an dessen Knoten wir jeweils über eine *V*-fache Kreuzvalidierung einen Kreuzvalidierungsfehler bestimmen werden. Zum Schluss werden wir das Parameterpaar $(Q^*, \\lambda^*)$ auswählen, für das der Kreuzvalidierungsfehler am kleinsten wird.\n",
    "\n",
    "* Diese Übung ist recht frei gehalten. Sie können sich gerne die übergeordneten Ziele der Übung ansehen und dann gleich mit Schritt (5) in die Implementierung starten.\n",
    "* Diejenigen unter Ihnen, die etwas Hilfestellung benötigen, werde ich in den unten stehenden Schritten (1)-(4) an die Implementierung mit verschiedenen Tipps heranführen.\n",
    "* Benutzen Sie in dieser Übung *nicht* Ihren eigenen früheren Code. Benutzen Sie stattdessen Befehle von Scikit-Learn und Numpy.\n",
    "\n",
    "**Übergeordnete Ziele** (weiter unten finden Sie diese Schritte detaillierter aufgeschlüsselt)\n",
    "1. Implementieren Sie mit Scikit-Learn eine Weight-Decay regularisierte lineare Regression mit polynomieller Feature Transformation. Skalieren Sie dabei die Features mit MinMax-Scaling (und verstehen Sie, was dies bedeutet). **Erzeugen Sie aus den Prozessierungsschritten eine Pipeline.**\n",
    "2. Führen Sie auf diesem Modell eine Hyperparametersuche mithilfe von *V*-facher Kreuzvalidierung für das Suchgitter $(\\lambda, Q)$ durch, mit $\\lambda \\in \\{0, 0.25, 0.5, \\ldots 5\\}$ und $Q = \\{1, \\ldots, 8 \\}$.\n",
    "3. Ihre Endprodukt ist eine Visualisierung des durch die *V*-fache Kreuzvalidierung ($V=5$) erhaltenen Kreuzvalidierungsfehler, aus dem Sie die optimalen Parameter $(\\lambda^*, Q^*)$ ablesen und angeben werden (wie in Übung 5.2 Schritt 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T09:51:27.695684Z",
     "start_time": "2019-07-21T09:51:27.234400Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "# Sie finden diese Daten auch zum Download unter: https://data.bialonski.de/ml/water-dam-data.mat\n",
    "file = requests.get('https://data.bialonski.de/ml/water-dam-data.mat')\n",
    "data = loadmat(BytesIO(file.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ihre Aufgaben**\n",
    "\n",
    "(1) Wir bauen zunächst gemeinsam an den einzelnen Schritten der Pipeline unseres Machine Learning Verfahrens. Machen Sie sich mit dem Interface des Objektes vertraut, das die [Skalierung der Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) übernimmt. Probieren Sie testweise aus, wie die Methoden `fit` und `transform` arbeiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Machen Sie sich mit dem Interface der [Polynomiellen Feature Transformation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) bekannt, die scikit-learn bereitstellt. Manche von Ihnen haben damit in der Vergangenheit bereits gearbeitet. Wie lässt sich der Grad des Polynoms einstellen? Nutzen Sie die Feature Transformation, um testweise Ihre aus dem Schritt (1) skalierten Features mit $Q=8$ zu transformieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "(3) Die lineare Regression mit Weight Decay wird auch *Ridge Regression* genannt. Machen Sie sich mit der [Implementierung dieses Lernmodels](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) in scikit-learn vertraut. Mit welchem Parameter können Sie die Regularisierungsstärke $\\lambda$ einstellen? Fitten Sie testweise einmal dieses Modell mit $\\lambda=0$ (Methode `fit`), an die Daten die Sie in Schritt (2) transformiert hatten."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Erzeugen Sie mit der Methode `predict` Vorhersagen auf Ihren Trainingsdaten. Visualisieren Sie sich die Vorhersagen und die echten Labels in einem Plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Die in (1)-(3) durchgeführten Schritte (`MinMaxScaler, PolynomialFeature, Ridge`) können als Transformationen der Ursprungsfeatures aufgefasst werden. Wir werden diese Schritte in einer sogenannten *Pipeline* zusammenfassen. Machen Sie sich mit [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) und ihrer Schnittstelle bei scikit-learn vertraut, um die Schritte (1)-(3) in einer Pipeline zusammenzufassen. Dieses [Beispiel](https://scikit-learn.org/stable/modules/compose.html#construction) verdeutlicht die Konstruktion der Pipeline als `(key,value)` Paare in einem `list` Objekt. Die Namen, die Sie den einzelnen Schritten geben können, werden in der nächsten Aufgabe benötigt.\n",
    "Fitten Sie testweise diese Pipeline an Ihre Trainingsdaten (Methode `fit`) und lassen Sie Ihre trainierte Pipeline aus den Trainingsfeatures die Labels (y-Werte) vorhersagen (Methode `predict`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Wir benutzen nun die Pipeline, um eine Gittersuche samt *V*-facher Kreuzvalidierung durchzuführen. Dazu machen Sie sich bitte mit [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) vertraut. [Dieses](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py) Beispiel und die folgenden Hinweise könnten dazu hilfreich sein:\n",
    "* Als `estimator` Objekt kann die eben konstruierte Pipeline übergeben werden.\n",
    "* Die Suchparameter (`param_grid`) werden in Dictionaries definiert;\n",
    "    * Die Schlüssel sind nach folgendem Schema aufgebaut: 'name__parameter'. Mit *name* sind die von Ihnen definierten Namen der Pipeline Schritte aus der letzten Teilaufgabe gemeint. Mit *parameter* der Parameter des jeweiligen `estimator`.\n",
    "    * Definieren Sie ein Suchparameter-Dictionary mit $\\lambda \\in \\{0, 0.25, 0.5, \\ldots 5\\}$ und $Q=8$.\n",
    "* Setzen Sie die Anzahl der Folds $V=5$.\n",
    "* Nutzen Sie als Scoring Function die Option 'neg_mean_squared_error'.\n",
    "\n",
    "Benutzen Sie die Methode `fit` um die Pipeline für alle Parameter des Grids an die Trainingsdaten zu fitten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "(7) Die Methode `.cv_results_` liefert Ihnen die Ergebnisse der Gittersuche. Untersuchen Sie diese Ergebnisse und entwickeln Sie ein Verständnis dafür, wo Sie welche Ergebnisse finden. Dabei könnte es Ihnen helfen, die `.cv_results_` in ein [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) `pd.DataFrame` umzuwandeln. Extrahieren Sie die Kreuzvalidierungsfehler aus `.cv_results_` und plotten Sie sie als Funktion des Regularisierungsparameters $\\lambda$."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Bauen Sie auf den Ergebnissen des Schritts (6) auf und implementieren nun eine Gittersuche, die das Gitter für $\\lambda$ und $Q$ in dem Bereich untersucht, der bei den übergeordneten Zielen definiert ist. Extrahieren Sie den Kreuzvalidierungsfehler für jeden Punkt des Gitters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) Visualisieren Sie mit [plt.imshow](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) die Kreuzvalidierungsfehler, die ihre Gittersuche ergeben hat. Bedenken Sie dabei, dass Sie in Schritt (6) als Scoring-Function den negativen mittleren quadratischen Fehler ausgewählt haben ('neg_mean_squared_error'). Sie müssen also für die Darstellung des gemittelten quadratischen Fehlers (den Sie aus der Vorlesung kennen) die erhaltenen Werte noch mit dem Faktor \"-1\" multiplizieren. Welche optimalen Parameter $(\\lambda^*, Q^*)$ haben Sie ermittelt (`.best_params_`)?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
